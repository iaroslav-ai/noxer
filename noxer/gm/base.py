from sklearn.base import BaseEstimator, TransformerMixin
from noxer.sequences import FlattenShape
from .metrics import distribution_similarity
from sklearn.preprocessing import StandardScaler

class GeneratorMixin(BaseEstimator):
    """
    A base class for generator classes.
    Implements a set of useful methods and variables, such
    that preprocessing of the data can be done using scikit-learn
    like class instances.

    Parameters
    ----------
    X_prep : TransformerMixin
        Class instance that will be fitted to the condition input X
        for the generator. This transformer is applied to the condition
        input X before it is fed into generative model.

    Y_prep : TransformerMixin
        Class instance that will be fitted to the output values Y
        for the generator. This transformer is applied to the values of
        Y when it is used for training.

    Y_post : TransformerMixin
        Class instance that will be fitted to the output values Y
        for the generator. This transformer is applied after the values
        are generated.
    """

    _estimator_type = "generator"

    def __init__(self, X_prep=None, Y_prep=None, Y_post=None):
        # Check input arguments to be instance of transformers
        if not (X_prep is None or isinstance(X_prep, TransformerMixin)):
            raise ValueError('X_prep should be instance of transformer.')

        if not (Y_prep is None or isinstance(Y_prep, TransformerMixin)):
            raise ValueError('Y_prep should be instance of transformer.')

        if not (Y_post is None or isinstance(Y_post, TransformerMixin)):
            raise ValueError('Y_post should be instance of transformer.')

        self.X_prep = X_prep
        self.Y_prep = Y_prep
        self.Y_post = Y_post

    def set_params(self, **params):
        """
        Custom setting of parameters for generative models.
        All parameters that start with 'x_prep', 'y_prep', 'y_post' are
        delegated to respective preprocessors.
        """

        if isinstance(self.X_prep, BaseEstimator):
            self.X_prep.set_params(**{k[len('x_prep')+2:]:v for k, v in params.items() if k.startswith('x_prep')})

        if isinstance(self.Y_prep, BaseEstimator):
            self.Y_prep.set_params(**{k[len('y_prep')+2:]:v for k, v in params.items() if k.startswith('y_prep')})

        if isinstance(self.Y_post, BaseEstimator):
            self.Y_post.set_params(**{k[len('y_post')+2:]:v for k, v in params.items() if k.startswith('y_post')})

        params = {
            k:v for k, v in params.items()
            if not any(
                k.startswith(v) for v in {'x_prep', 'y_prep', 'y_post'}
            )
        }
        BaseEstimator.set_params(self, **params)

    def _fit_preprocessors(self, X, Y):
        """Fits all preprocessors to the data.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.
        """
        if self.X_prep is not None:
            X = self.X_prep.fit_transform(X)

        if self.Y_post is not None:
            self.Y_post.fit(Y)

        if self.Y_prep is not None:
            Y = self.Y_prep.fit_transform(Y)

        return X, Y

    def _transform_inputs(self, X, Y=None):
        """Transforms inputs so that they can be used for estimations
        with generative model

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.
        """
        if self.X_prep is not None:
            X = self.X_prep.transform(X)

        if Y is None:
            return X

        if self.Y_prep is not None:
            Y = self.Y_prep.transform(Y)

        return X, Y

    def _transform_generated_outputs(self, Y):
        """Apply output transformers to the generated values

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.
        """
        if self.Y_prep is not None:
            Y = self.Y_prep.inverse_transform(Y)

        if self.Y_post is not None:
            Y = self.Y_post.transform(Y)

        return Y

    def _predict(self, X, *args, **kwargs):
        """
        Abstract sample generation method method that should be
        implemented by different methods.


        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        """
        raise NotImplementedError("Implement your predict method")

    def _fit(self, X, Y, *args, **kwargs):
        """
        Fits generative model to the dataset of conditions and
        example outputs.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.
        """
        raise NotImplementedError("Implement your predict method")

    def fit(self, X, Y, *args, **kwargs):
        """
        Complete fitting pipeline with data preprocessing for generative
        models.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.
        """
        X, Y = self._fit_preprocessors(X, Y)
        self._fit(X, Y, *args, **kwargs)
        return self

    def predict(self, X, *args, **kwargs):
        """
        Full generation pipeline with all necessary steps such as data
        preprocessing.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        """
        X = self._transform_inputs(X)
        Y = self._predict(X, *args, **kwargs)
        Y = self._transform_generated_outputs(Y)
        return Y

    def score(self, X, Y, p_kwargs={}, s_kwargs={}):
        """
        Evaluates the quality of the model using comparison
        to real data.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.

        Returns
        -------
        score : float
            Similarity of obtained distributions
        """

        Yp = self.predict(X, **p_kwargs)
        s_kwargs['X_true'] = Y
        s_kwargs['X_pred'] = Yp

        score = distribution_similarity(**s_kwargs)
        return score


