from sklearn.base import BaseEstimator, TransformerMixin
from noxer.sequences import FlattenShape
from .metrics import distribution_similarity
from sklearn.preprocessing import StandardScaler

class IOTransform(BaseEstimator):
    """
    A base class for generator classes.
    Implements a set of useful methods and variables, such
    that preprocessing of the data can be done using scikit-learn
    like class instances.

    Parameters
    ----------
    X_prep : BaseEstimator
        Class instance that will be fitted to the condition input X
        for the generator. This transformer is applied to the condition
        input X before it is fed into generative model.

    Y_prep : BaseEstimator
        Class instance that will be fitted to the output values Y
        for the generator. This transformer is applied to the values of
        Y when it is used for training.

    Y_post : BaseEstimator
        Class instance that will be fitted to the output values Y
        for the generator. This transformer is applied after the values
        are generated.

    model : BaseEstimator
        Instance of a class that is used for mapping from inputs to
        outputs.

    model : callable with two arguments
        Scorer that is used to evaluate predictions of the model

    """

    _estimator_type = "generator"

    def __init__(self, model, metric, X_prep=None, Y_prep=None, Y_post=None):
        self.X_prep = X_prep
        self.Y_prep = Y_prep
        self.Y_post = Y_post

        if not isinstance(model, BaseEstimator):
            raise TypeError('Model should be an instance of BaseEstimator, got %s' % model)

        self.model = model
        self.metric = metric

    def set_params(self, **params):
        """
        Custom setting of parameters for generative models.
        All parameters that start with 'x_prep', 'y_prep', 'y_post' are
        delegated to respective preprocessors.
        """

        params = {
            k:v for k, v in params.items()
            if not any(
                k.startswith(v) for v in {'x_prep', 'y_prep', 'y_post', 'model'}
            )
        }
        BaseEstimator.set_params(self, **params)

        if isinstance(self.X_prep, BaseEstimator):
            self.X_prep.set_params(**{k[len('x_prep')+2:]:v for k, v in params.items() if k.startswith('x_prep')})

        if isinstance(self.Y_prep, BaseEstimator):
            self.Y_prep.set_params(**{k[len('y_prep')+2:]:v for k, v in params.items() if k.startswith('y_prep')})

        if isinstance(self.Y_post, BaseEstimator):
            self.Y_post.set_params(**{k[len('y_post')+2:]:v for k, v in params.items() if k.startswith('y_post')})

        self.model.set_params(**{k[len('model')+2:]:v for k, v in params.items() if k.startswith('model')})



    def _fit_preprocessors(self, X, Y):
        """Fits all preprocessors to the data.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.
        """
        if self.X_prep is not None:
            X = self.X_prep.fit_transform(X, Y)

        if self.Y_post is not None:
            self.Y_post.fit(Y, X)

        if self.Y_prep is not None:
            Y = self.Y_prep.fit_transform(Y, X)

        return X, Y

    def _transform_inputs(self, X, Y=None):
        """Transforms inputs so that they can be used for estimations
        with generative model

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.
        """
        if self.X_prep is not None:
            # account for some transformers taking only single argument
            if 'Y' in self.X_prep.transform.__code__.co_varnames:
                X = self.X_prep.transform(X, Y)
            else:
                X = self.X_prep.transform(X)

        if Y is None:
            return X

        if self.Y_prep is not None:
            # account for some transformers taking only single argument
            if 'Y' in self.Y_prep.transform.__code__.co_varnames:
                Y = self.Y_prep.transform(Y, X)
            else:
                Y = self.Y_prep.transform(Y)

        return X, Y

    def _transform_generated_outputs(self, Y, X=None):
        """Apply output transformers to the generated values

        Parameters
        ----------
        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.

        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.
        """
        if self.Y_prep is not None:
            if 'Y' in self.Y_prep.inverse_transform.__code__.co_varnames:
                Y = self.Y_prep.inverse_transform(Y, X)
            else:
                Y = self.Y_prep.inverse_transform(Y)

        if self.Y_post is not None:
            if 'Y' in self.Y_post.transform.__code__.co_varnames:
                Y = self.Y_post.transform(Y, X)
            else:
                Y = self.Y_post.transform(Y)

        return Y

    def fit(self, X, Y, *args, **kwargs):
        """
        Complete fitting pipeline with data preprocessing for generative
        models.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.
        """
        X, Y = self._fit_preprocessors(X, Y)
        self.model.fit(X, Y, *args, **kwargs)
        return self

    def predict(self, X, *args, **kwargs):
        """
        Full generation pipeline with all necessary steps such as data
        preprocessing.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        """
        X = self._transform_inputs(X)
        Y = self.model.predict(X, *args, **kwargs)
        Y = self._transform_generated_outputs(Y, X)
        return Y

    def score(self, X, Y, *args, **kwargs):
        """
        Evaluates the quality of the model using comparison
        to real data.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.

        Returns
        -------
        score : float
            Similarity of obtained distributions
        """

        Yp = self.predict(X, *args, **kwargs)
        score = self.metric(Y, Yp)
        return score


class GeneratorBase(BaseEstimator):
    def fit(self, X, Y, **kwargs):
        """Fit generative model to the data.

        Parameters
        ----------
        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.

        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.
        """
        raise NotImplementedError("Please implement a fit method for your model.")

    def predict(self, X, **kwargs):
        """Make estimations with generative model.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.

        Returns
        -------
        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that is generated by a generative model.

        """
        raise NotImplementedError("Please implement a fit method for your model.")

    def score(self, X, Y, **kwargs):
        """Score the generative model on the real data.

        Parameters
        ----------
        Y : {array-like, sparse matrix}, shape [n_samples, ...]
            The data that should be generated by particular model.

        X : {array-like, sparse matrix}, shape [n_samples, ...]
            The data used to condition the generative model's outputs.
        """
        Yp = self.predict(X, **kwargs)
        score = distribution_similarity(Y, Yp)
        return score